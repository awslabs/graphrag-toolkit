{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bfeb79c9431a3c6",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This notebook sets up the development environment for lexical-graph examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dev_mode_check",
   "metadata": {},
   "source": [
    "## Check Development Mode\n",
    "\n",
    "First, let's check if we're running in development mode with hot-code-injection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_dev_mode",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if lexical-graph source is mounted\n",
    "lexical_graph_path = '/home/jovyan/lexical-graph-src'\n",
    "dev_mode = os.path.exists(lexical_graph_path)\n",
    "\n",
    "if dev_mode:\n",
    "    print('Development mode detected!')\n",
    "    print(f'Lexical-graph source mounted at: {lexical_graph_path}')\n",
    "    \n",
    "    # Add to Python path for hot-code-injection\n",
    "    if lexical_graph_path not in sys.path:\n",
    "        sys.path.insert(0, lexical_graph_path)\n",
    "        print('Added lexical-graph to Python path for hot-code-injection')\n",
    "else:\n",
    "    print('Standard mode - using installed packages')\n",
    "    print('To enable development mode, restart with: ./start-containers.sh --dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install_deps",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dev_mode:\n",
    "    print('Installing lexical-graph package...')\n",
    "    !pip install https://github.com/awslabs/graphrag-toolkit/archive/refs/tags/v3.11.0.zip#subdirectory=lexical-graph\n",
    "else:\n",
    "    print('Development mode - will install from mounted source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fix_nltk",
   "metadata": {},
   "source": [
    "## Fix NLTK Data\n",
    "\n",
    "Download required NLTK data to prevent processing errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nltk_fix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "# Handle SSL certificate issues\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "print('NLTK data downloaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hot_reload",
   "metadata": {},
   "source": [
    "## Hot-Reload Setup (Development Mode)\n",
    "\n",
    "If in development mode, set up hot-reloading for lexical-graph modules:\n",
    "\n",
    "**IMPORTANT**: After running this cell in development mode, you must restart the kernel (Kernel → Restart Kernel) before continuing to the next cells.\n",
    "\n",
    "**NOTE**: This installation process can sometimes fail or hang. If it doesn't complete within 2-3 minutes, interrupt the kernel and try running this cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_hot_reload",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_mode:\n",
    "    print('Setting up hot-reload for lexical-graph modules...')\n",
    "    \n",
    "    # Install lexical-graph in editable mode from mounted source\n",
    "    try:\n",
    "        import subprocess\n",
    "        import time\n",
    "        print('Installing lexical-graph in editable mode (this may take 60-90 seconds)...')\n",
    "        print('Please wait - installation in progress', end='', flush=True)\n",
    "        \n",
    "        # Run pip install with real-time feedback\n",
    "        process = subprocess.Popen(['pip', 'install', '-e', '/home/jovyan/lexical-graph-src'], \n",
    "                                 stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                                 universal_newlines=True, bufsize=1)\n",
    "        \n",
    "        # Show progress with timeout\n",
    "        import threading\n",
    "        progress_active = True\n",
    "        \n",
    "        def show_progress():\n",
    "            count = 0\n",
    "            while progress_active and count < 60:  # Max 60 seconds (30 * 2)\n",
    "                print('.', end='', flush=True)\n",
    "                time.sleep(2)\n",
    "                count += 1\n",
    "            if count >= 60:\n",
    "                print('\\nInstallation taking longer than expected, but still running...')\n",
    "        \n",
    "        progress_thread = threading.Thread(target=show_progress)\n",
    "        progress_thread.start()\n",
    "        \n",
    "        # Wait for completion\n",
    "        stdout, _ = process.communicate()\n",
    "        progress_active = False\n",
    "        progress_thread.join()\n",
    "        print()  # New line after dots\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            print('Installed lexical-graph in editable mode')\n",
    "        else:\n",
    "            print('Could not install in editable mode, using Python path instead')\n",
    "    except Exception as e:\n",
    "        print(f'Installation failed: {e}')\n",
    "    \n",
    "    # Enable autoreload\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "    print('Hot-reload configured - modules will auto-reload on changes!')\n",
    "    print('Tip: Use %autoreload 2 in cells where you want fresh imports')\n",
    "    print('')\n",
    "    print('IMPORTANT: You must restart the kernel now for the editable installation to take effect.')\n",
    "    print('   Go to Kernel → Restart Kernel, then continue with the remaining cells.')\n",
    "else:\n",
    "    print('Hot-reload not available in standard mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_env",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfdf2594abab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Re-check dev mode after kernel restart\n",
    "lexical_graph_path = '/home/jovyan/lexical-graph-src'\n",
    "dev_mode = os.path.exists(lexical_graph_path)\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.neo4j_graph_store_factory import Neo4jGraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph import set_logging_config\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "# Register the Neo4j backend with the factory\n",
    "GraphStoreFactory.register(Neo4jGraphStoreFactory)\n",
    "\n",
    "print('Development environment setup complete!')\n",
    "print(f'Graph Store: {os.environ.get(\"GRAPH_STORE\", \"Not configured\")}')\n",
    "print(f'Vector Store: {os.environ.get(\"VECTOR_STORE\", \"Not configured\")}')\n",
    "\n",
    "if dev_mode:\n",
    "    print('\\nHot-code-injection enabled - changes to lexical-graph source will be reflected immediately!')\n",
    "    print('Auto-reload is active - modules will refresh automatically')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a7a35-c25d-472a-944d-f18ea3a48c44",
   "metadata": {},
   "source": [
    "## Verify AWS Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8d5fc-e145-4340-8901-2cd3bfe20701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "print('Testing AWS access...')\n",
    "\n",
    "# Check if AWS_PROFILE is set\n",
    "aws_profile = os.environ.get('AWS_PROFILE')\n",
    "if aws_profile:\n",
    "    print(f'Using AWS profile: {aws_profile}')\n",
    "    session = boto3.Session(profile_name=aws_profile)\n",
    "else:\n",
    "    print('Using default AWS credentials')\n",
    "    session = boto3.Session()\n",
    "\n",
    "try:\n",
    "    # Test STS access to get caller identity\n",
    "    sts = session.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    \n",
    "    print('AWS access successful!')\n",
    "    print(f'Account: {identity[\"Account\"]}')\n",
    "    print(f'User/Role: {identity[\"Arn\"]}')\n",
    "    \n",
    "    # Test Bedrock access\n",
    "    bedrock = session.client('bedrock', region_name=os.environ.get('AWS_REGION', 'us-east-1'))\n",
    "    models = bedrock.list_foundation_models()\n",
    "    \n",
    "    print('Bedrock access successful!')\n",
    "    print(f'Available models: {len(models[\"modelSummaries\"])}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'AWS access failed: {e}')\n",
    "    print('Check your AWS credentials and profile configuration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca4ac2-2e46-4783-aca7-15619baeffec",
   "metadata": {},
   "source": [
    "## Readers Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cea045-97be-4586-bef7-5939828e8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PDF processing dependencies\n",
    "!pip install llama-index-readers-file pymupdf\n",
    "\n",
    "print('PDF processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1a81c-1a45-43c9-838f-10f0c48beb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YouTube processing dependencies\n",
    "!pip install youtube-transcript-api\n",
    "\n",
    "print('YouTube processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5d48e-a3c4-49b1-9e76-e3790968e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DOCX processing dependencies\n",
    "!pip install docx2txt\n",
    "\n",
    "print('DOCX processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d57a22-c799-405f-8919-2890781a1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GitHub processing dependencies\n",
    "!pip install PyGithub\n",
    "!pip install llama-index-readers-github\n",
    "!pip install nest_asyncio\n",
    "\n",
    "# Add this at the top of your GitHub reader cell\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print('GitHub processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e20873-eb8a-41e0-94fb-395981f5f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PPTX processing dependencies\n",
    "!pip install torch \"transformers<=4.50\" python-pptx Pillow\n",
    "\n",
    "print('PPTX processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90c933-a5da-4e53-b685-a6a472cb8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install JSON processing dependencies\n",
    "!pip install llama-index-readers-json\n",
    "\n",
    "print('JSON processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdafe2-1700-46f3-8be8-5daa3a0596f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Structured-Data processing dependencies\n",
    "!pip install llama-index-readers-structured-data pandas openpyxl\n",
    "print('Structured-Data processing dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee8f51-0956-4efa-a225-e28ab524ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support for S3 Directory Reader\n",
    "!pip install boto3\n",
    "!pip install llama-index-readers-s3\n",
    "\n",
    "print('S3 Directory Reader installed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
