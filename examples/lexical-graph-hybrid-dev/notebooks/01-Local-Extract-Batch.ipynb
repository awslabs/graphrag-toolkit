{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434fea4e",
   "metadata": {},
   "source": [
    "# 02 - Separate Extract and Build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb5cff",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you haven't already, install the toolkit and dependencies using the [Setup](./00-Setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfff49b",
   "metadata": {},
   "source": [
    "## Local extract to folder\n",
    "\n",
    "See [Run the extract and build stages separately](https://github.com/awslabs/graphrag-toolkit/blob/main/docs/lexical-graph/indexing.md#run-the-extract-and-build-stages-separately)"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b26157e-277f-4c23-979b-e933b38501bb",
   "metadata": {},
   "source": [
    "import logging\n",
    "\n",
    "# Suppress Neo4j notifications/warnings\n",
    "logging.getLogger('neo4j.notifications').setLevel(logging.ERROR)\n",
    "logging.getLogger('neo4j').setLevel(logging.ERROR)\n",
    "\n",
    "# Or suppress all Neo4j logging completely\n",
    "logging.getLogger('neo4j').disabled = True\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79b6c7bd",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.neo4j_graph_store_factory import Neo4jGraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphIndex, set_logging_config\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.indexing.load import FileBasedDocs\n",
    "from graphrag_toolkit.lexical_graph.indexing.build import Checkpoint\n",
    "\n",
    "# Import GraphRAG web reader instead of LlamaIndex directly\n",
    "from graphrag_toolkit.lexical_graph.indexing.load.readers import WebReaderProvider, WebReaderConfig\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "# Register the Neo4j backend with the factory\n",
    "GraphStoreFactory.register(Neo4jGraphStoreFactory)\n",
    "\n",
    "extracted_docs = FileBasedDocs(\n",
    "    docs_directory='extracted'\n",
    ")\n",
    "\n",
    "checkpoint = Checkpoint('extraction-checkpoint')\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store, \n",
    "    vector_store\n",
    ")\n",
    "\n",
    "doc_urls = [\n",
    "    'https://docs.aws.amazon.com/neptune/latest/userguide/intro.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-features.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-vs-neptune-database.html'\n",
    "]\n",
    "\n",
    "# Configure web reader with metadata function\n",
    "web_config = WebReaderConfig(\n",
    "    html_to_text=True,\n",
    "    metadata_fn=lambda url: {'url': url, 'source': 'web', 'domain': 'aws.amazon.com'}\n",
    ")\n",
    "\n",
    "web_reader = WebReaderProvider(web_config)\n",
    "\n",
    "# Read documents using GraphRAG web reader\n",
    "docs = web_reader.read(doc_urls)\n",
    "\n",
    "graph_index.extract(docs, handler=extracted_docs, checkpoint=checkpoint, show_progress=True)\n",
    "\n",
    "collection_id = extracted_docs.collection_id\n",
    "\n",
    "print('Extraction complete')\n",
    "print(f'collection_id: {collection_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5ed8c34f6f937fb",
   "metadata": {},
   "source": [
    "## Extraction to S3\n",
    "\n",
    "See [Run the extract and build stages separately](https://github.com/awslabs/graphrag-toolkit/blob/main/docs/lexical-graph/indexing.md#run-the-extract-and-build-stages-separately)"
   ]
  },
  {
   "cell_type": "code",
   "id": "917e0345c606995f",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.neo4j_graph_store_factory import Neo4jGraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphIndex, set_logging_config\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.indexing.load import S3BasedDocs\n",
    "from graphrag_toolkit.lexical_graph.indexing.build import Checkpoint\n",
    "\n",
    "# Import GraphRAG web reader instead of LlamaIndex directly\n",
    "from graphrag_toolkit.lexical_graph.indexing.load.readers import WebReaderProvider, WebReaderConfig\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "# Register the Neo4j backend with the factory\n",
    "GraphStoreFactory.register(Neo4jGraphStoreFactory)\n",
    "\n",
    "extracted_docs = S3BasedDocs(\n",
    "    region=os.environ['AWS_REGION'],\n",
    "    bucket_name=os.environ['S3_BUCKET_EXTRACK_BUILD_BATCH_NAME'],\n",
    "    key_prefix=os.environ[\"EXTRACT_BUILD_PREFIX\"],\n",
    "    collection_id='web-docs'\n",
    ")\n",
    "\n",
    "checkpoint = Checkpoint('s3-extraction-web-docs-checkpoint-01')\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store,\n",
    "    vector_store\n",
    ")\n",
    "\n",
    "doc_urls = [\n",
    "    'https://docs.aws.amazon.com/neptune/latest/userguide/intro.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/what-is-neptune-analytics.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-features.html',\n",
    "    'https://docs.aws.amazon.com/neptune-analytics/latest/userguide/neptune-analytics-vs-neptune-database.html'\n",
    "]\n",
    "\n",
    "# Configure web reader with metadata function\n",
    "web_config = WebReaderConfig(\n",
    "    html_to_text=True,\n",
    "    metadata_fn=lambda url: {\n",
    "        'url': url, \n",
    "        'source': 'web', \n",
    "        'domain': 'aws.amazon.com',\n",
    "        'document_type': 'documentation'\n",
    "    }\n",
    ")\n",
    "\n",
    "web_reader = WebReaderProvider(web_config)\n",
    "\n",
    "# Read documents using GraphRAG web reader\n",
    "docs = web_reader.read(doc_urls)\n",
    "\n",
    "graph_index.extract(docs, handler=extracted_docs, checkpoint=checkpoint, show_progress=True)\n",
    "\n",
    "collection_id = extracted_docs.collection_id\n",
    "\n",
    "print('Extraction complete')\n",
    "print(f'collection_id: {collection_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc6568641b03d2da",
   "metadata": {},
   "source": [
    "## Using batch inference with the LexicalGraphIndex. Writing to AWS S3 and DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19fc7db1fd8061",
   "metadata": {},
   "source": [
    "Ensure you have reviewed batch-extraction.md. For permission creation please see setup-bedrock-batch.md in lexical-graph-hybrid-dev/aws folder."
   ]
  },
  {
   "cell_type": "code",
   "id": "13f0f063fc01eb06",
   "metadata": {},
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "from graphrag_toolkit.lexical_graph import (\n",
    "    GraphRAGConfig,\n",
    "    IndexingConfig\n",
    "    )\n",
    "\n",
    "from graphrag_toolkit.lexical_graph.storage.graph.neo4j_graph_store_factory import Neo4jGraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph import LexicalGraphIndex, set_logging_config\n",
    "from graphrag_toolkit.lexical_graph.storage import GraphStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.storage import VectorStoreFactory\n",
    "from graphrag_toolkit.lexical_graph.indexing.load import S3BasedDocs\n",
    "from graphrag_toolkit.lexical_graph.indexing.build import Checkpoint\n",
    "from graphrag_toolkit.lexical_graph.indexing.extract import BatchConfig\n",
    "\n",
    "# Import GraphRAG readers instead of LlamaIndex directly\n",
    "from graphrag_toolkit.lexical_graph.indexing.load.readers import (\n",
    "    DirectoryReaderProvider, DirectoryReaderConfig,\n",
    "    PDFReaderProvider, PDFReaderConfig\n",
    ")\n",
    "\n",
    "set_logging_config('INFO')\n",
    "\n",
    "# Set batch size\n",
    "GraphRAGConfig.extraction_batch_size = int(os.environ.get(\"EXTRACTION_BATCH_SIZE\", 4))\n",
    "\n",
    "# Configure batch S3 setup\n",
    "batch_config = BatchConfig(\n",
    "        region=os.environ[\"AWS_REGION\"],\n",
    "        bucket_name=os.environ[\"S3_BUCKET_EXTRACK_BUILD_BATCH_NAME\"],\n",
    "        key_prefix=os.environ[\"BATCH_PREFIX\"],\n",
    "        role_arn=f'arn:aws:iam::{os.environ[\"AWS_ACCOUNT\"]}:role/{os.environ[\"BATCH_ROLE_NAME\"]}',\n",
    "    )\n",
    "\n",
    "indexing_config = IndexingConfig(batch_config=batch_config)\n",
    "\n",
    "# Register the Neo4j backend with the factory\n",
    "GraphStoreFactory.register(Neo4jGraphStoreFactory)\n",
    "\n",
    "extracted_docs = S3BasedDocs(\n",
    "    region=os.environ['AWS_REGION'],\n",
    "    bucket_name=os.environ['S3_BUCKET_EXTRACK_BUILD_BATCH_NAME'],\n",
    "    key_prefix=os.environ[\"EXTRACT_BUILD_PREFIX\"],\n",
    "    collection_id='best-practices'\n",
    ")\n",
    "\n",
    "# Create checkpoint\n",
    "checkpoint = Checkpoint('extraction-best-practices-checkpoint-01')\n",
    "\n",
    "graph_store = GraphStoreFactory.for_graph_store(os.environ['GRAPH_STORE'])\n",
    "vector_store = VectorStoreFactory.for_vector_store(os.environ['VECTOR_STORE'])\n",
    "\n",
    "graph_index = LexicalGraphIndex(\n",
    "    graph_store,\n",
    "    vector_store,\n",
    "    indexing_config=indexing_config\n",
    ")\n",
    "\n",
    "# Configure directory reader with PDF support\n",
    "directory_config = DirectoryReaderConfig(\n",
    "    input_dir=os.environ[\"SOURCE_DIR\"],\n",
    "    recursive=True,\n",
    "    required_exts=[\".pdf\"],  # Only process PDF files\n",
    "    metadata_fn=lambda path: {\n",
    "        'source': 'directory',\n",
    "        'file_path': path,\n",
    "        'document_type': 'best_practices',\n",
    "        'collection': 'best-practices'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure PDF reader for better PDF processing\n",
    "pdf_config = PDFReaderConfig(\n",
    "    return_full_document=False,  # Split into chunks\n",
    "    metadata_fn=lambda path: {\n",
    "        'source': 'pdf',\n",
    "        'file_path': path,\n",
    "        'document_type': 'best_practices'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create directory reader\n",
    "directory_reader = DirectoryReaderProvider(directory_config)\n",
    "\n",
    "# Read all documents from directory\n",
    "docs = directory_reader.read(os.environ[\"SOURCE_DIR\"])\n",
    "\n",
    "graph_index.extract(docs, handler=extracted_docs, checkpoint=checkpoint, show_progress=True)\n",
    "\n",
    "collection_id = extracted_docs.collection_id\n",
    "\n",
    "print('Extraction complete')\n",
    "print(f'collection_id: {collection_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
